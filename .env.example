# by default the Dockerfile specifies these versions: 3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX
# however for me to work i had to specify the exact version for my card ( 2060 ) it was 7.5
# https://developer.nvidia.com/cuda-gpus you can find the version for your card here
TORCH_CUDA_ARCH_LIST=7.5

# this is an example using 4bits limited to < 4GB of vram, this should allow most people to run it.
CLI_ARGS=--model llama-7b-hf --gptq-bits 4 --gptq-pre-layer 20 --listen --auto-devices